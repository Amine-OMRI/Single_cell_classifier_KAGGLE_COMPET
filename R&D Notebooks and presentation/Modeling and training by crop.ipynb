{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b254569f",
   "metadata": {},
   "source": [
    "# Imports and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087c6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0efc7c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a35c2e2",
   "metadata": {},
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29cb72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_folder = \"data/\"\n",
    "crop_folder_ssd = \"C:/cell_crops/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6532fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Nucleoplasm\",\n",
    "\"Nuclear membrane\",\n",
    "\"Nucleoli\",\n",
    "\"Nucleoli fibrillar center\",\n",
    "\"Nuclear speckles\",\n",
    "\"Nuclear bodies\",\n",
    "\"Endoplasmic reticulum\",\n",
    "\"Golgi apparatus\",\n",
    "\"Intermediate filaments\",\n",
    "\"Actin filaments\",\n",
    "\"Microtubules\",\n",
    "\"Mitotic spindle\",\n",
    "\"Centrosome\",\n",
    "\"Plasma membrane\",\n",
    "\"Mitochondria\",\n",
    "\"Aggresome\",\n",
    "\"Cytosol\",\n",
    "\"Vesicles and punctate cytosolic patterns\",\n",
    "\"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e39e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 410\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "# After tries, I found i could prefetch less than 20'500 crops in memory.\n",
    "MAX_CROPS_PREFETCHED = 4096\n",
    "# 12288 Doesn't seem to work with test prefetched as well\n",
    "# 8192 # Success with only half the cache used\n",
    "#16384 # Crashes 1687/6207 (27%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1f21db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1b0423daee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.models.load_model(\"models/default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e3940",
   "metadata": {},
   "source": [
    "# Designing the model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ab90313",
   "metadata": {},
   "source": [
    "# dummy\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input((SIZE, SIZE, 3)))\n",
    "model.add(layers.Lambda(lambda x: tf.random.uniform([BATCH_SIZE, 19])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a448d47",
   "metadata": {},
   "source": [
    "# https://core.ac.uk/download/pdf/237216276.pdf\n",
    "# page 121\n",
    "MODEL_NAME = \"fungus_like\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8340d0e",
   "metadata": {},
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(SIZE, SIZE, 3), batch_size = None))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(len(classes), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "117c7f80",
   "metadata": {},
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(len(classes), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a68d756",
   "metadata": {},
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(layers.Dense(len(classes), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5806462f",
   "metadata": {},
   "source": [
    "NAME = \"conv_deep\" # deep\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(SIZE, SIZE, 3)))\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(256, (5, 5), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(512, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(layers.Dense(len(classes), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa1060ef",
   "metadata": {},
   "source": [
    "CONV_NAME = \"conv_basic\"\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (5, 5), activation='relu', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(len(classes), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d4595be",
   "metadata": {},
   "source": [
    "NAME = \"conv_smaller\"\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (5, 5), activation='relu', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(len(classes), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6456f4eb",
   "metadata": {},
   "source": [
    "NAME = \"conv_smaller_2\"\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (5, 5), activation='relu', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(len(classes), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "489d39bf",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c72c5a7",
   "metadata": {},
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22115e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc39109",
   "metadata": {},
   "source": [
    "# Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545c4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(metadata_folder+\"train_bboxes.csv\", index_col=\"ID\").rename(columns={\"Unnamed: 0\": \"new_index\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32f2e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = len(set(df.Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a14f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221140484096"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.image_height*df.image_width).sum()*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e6edf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_index</th>\n",
       "      <th>old_index</th>\n",
       "      <th>Label</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "      <th>boxes_height</th>\n",
       "      <th>boxes_width</th>\n",
       "      <th>boxes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5e22a522-bb99-11e8-b2b9-ac1f6b6435d0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>[217, 379, 207, 351, 307, 743, 399, 231, 255, ...</td>\n",
       "      <td>[583, 273, 367, 331, 139, 283, 383, 219, 499, ...</td>\n",
       "      <td>[[0, 217, 1798, 2381], [114, 493, 0, 273], [64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5f79a114-bb99-11e8-b2b9-ac1f6b6435d0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>[433, 599, 165, 558, 735, 771, 669, 583, 767, ...</td>\n",
       "      <td>[605, 606, 699, 609, 617, 447, 452, 469, 610, ...</td>\n",
       "      <td>[[0, 433, 0, 605], [0, 599, 568, 1174], [0, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5c801c04-bb99-11e8-b2b9-ac1f6b6435d0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>[249, 285, 315, 335, 306, 399, 415, 289, 277, ...</td>\n",
       "      <td>[331, 543, 537, 339, 275, 195, 319, 137, 276, ...</td>\n",
       "      <td>[[0, 249, 42, 373], [0, 285, 1894, 2437], [226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5e9afd56-bb99-11e8-b2b9-ac1f6b6435d0</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>[146, 261, 288, 368, 269, 211, 156, 208, 195, ...</td>\n",
       "      <td>[205, 209, 283, 129, 231, 179, 210, 162, 126, ...</td>\n",
       "      <td>[[0, 146, 455, 660], [0, 261, 635, 844], [5, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>[365, 525, 162, 273, 279, 323, 469, 310, 316, ...</td>\n",
       "      <td>[884, 415, 582, 708, 485, 429, 557, 286, 475, ...</td>\n",
       "      <td>[[0, 365, 0, 884], [0, 525, 766, 1181], [0, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9d99186-bbca-11e8-b2bc-ac1f6b6435d0</th>\n",
       "      <td>10407</td>\n",
       "      <td>21798</td>\n",
       "      <td>3</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>[845, 173, 299, 455, 587, 1127, 659, 811, 395,...</td>\n",
       "      <td>[1093, 607, 437, 655, 741, 387, 483, 265, 422,...</td>\n",
       "      <td>[[0, 845, 0, 1093], [0, 173, 1122, 1729], [70,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daa22470-bbca-11e8-b2bc-ac1f6b6435d0</th>\n",
       "      <td>10408</td>\n",
       "      <td>21799</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>[1149, 909, 439, 623, 940, 721, 625]</td>\n",
       "      <td>[463, 815, 735, 1057, 536, 223, 451]</td>\n",
       "      <td>[[0, 1149, 370, 833], [0, 909, 666, 1481], [75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc261180-bbca-11e8-b2bc-ac1f6b6435d0</th>\n",
       "      <td>10409</td>\n",
       "      <td>21800</td>\n",
       "      <td>6</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>[165, 288, 329, 275, 260, 259, 358, 431, 387, ...</td>\n",
       "      <td>[378, 182, 291, 411, 266, 157, 259, 291, 365, ...</td>\n",
       "      <td>[[0, 165, 78, 456], [0, 288, 459, 641], [0, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0</th>\n",
       "      <td>10410</td>\n",
       "      <td>21801</td>\n",
       "      <td>14</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>[357, 325, 425, 345, 515, 527, 251, 424, 343, ...</td>\n",
       "      <td>[399, 512, 591, 695, 461, 437, 333, 507, 615, ...</td>\n",
       "      <td>[[0, 357, 0, 399], [0, 325, 249, 761], [0, 425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df573730-bbca-11e8-b2bc-ac1f6b6435d0</th>\n",
       "      <td>10411</td>\n",
       "      <td>21804</td>\n",
       "      <td>14</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>[173, 281, 957, 84, 365, 337, 975, 404, 479, 6...</td>\n",
       "      <td>[968, 681, 803, 115, 308, 534, 347, 620, 319, ...</td>\n",
       "      <td>[[0, 173, 0, 968], [0, 281, 779, 1460], [0, 95...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10412 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      new_index  old_index  Label  \\\n",
       "ID                                                                  \n",
       "5e22a522-bb99-11e8-b2b9-ac1f6b6435d0          0          5      0   \n",
       "5f79a114-bb99-11e8-b2b9-ac1f6b6435d0          1          6     14   \n",
       "5c801c04-bb99-11e8-b2b9-ac1f6b6435d0          2          9     14   \n",
       "5e9afd56-bb99-11e8-b2b9-ac1f6b6435d0          3         10      0   \n",
       "5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0          4         11      3   \n",
       "...                                         ...        ...    ...   \n",
       "d9d99186-bbca-11e8-b2bc-ac1f6b6435d0      10407      21798      3   \n",
       "daa22470-bbca-11e8-b2bc-ac1f6b6435d0      10408      21799      0   \n",
       "dc261180-bbca-11e8-b2bc-ac1f6b6435d0      10409      21800      6   \n",
       "dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0      10410      21801     14   \n",
       "df573730-bbca-11e8-b2bc-ac1f6b6435d0      10411      21804     14   \n",
       "\n",
       "                                      image_height  image_width  \\\n",
       "ID                                                                \n",
       "5e22a522-bb99-11e8-b2b9-ac1f6b6435d0          3072         3072   \n",
       "5f79a114-bb99-11e8-b2b9-ac1f6b6435d0          2048         2048   \n",
       "5c801c04-bb99-11e8-b2b9-ac1f6b6435d0          3072         3072   \n",
       "5e9afd56-bb99-11e8-b2b9-ac1f6b6435d0          2048         2048   \n",
       "5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0          2048         2048   \n",
       "...                                            ...          ...   \n",
       "d9d99186-bbca-11e8-b2bc-ac1f6b6435d0          2048         2048   \n",
       "daa22470-bbca-11e8-b2bc-ac1f6b6435d0          2048         2048   \n",
       "dc261180-bbca-11e8-b2bc-ac1f6b6435d0          2048         2048   \n",
       "dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0          2048         2048   \n",
       "df573730-bbca-11e8-b2bc-ac1f6b6435d0          3072         3072   \n",
       "\n",
       "                                                                           boxes_height  \\\n",
       "ID                                                                                        \n",
       "5e22a522-bb99-11e8-b2b9-ac1f6b6435d0  [217, 379, 207, 351, 307, 743, 399, 231, 255, ...   \n",
       "5f79a114-bb99-11e8-b2b9-ac1f6b6435d0  [433, 599, 165, 558, 735, 771, 669, 583, 767, ...   \n",
       "5c801c04-bb99-11e8-b2b9-ac1f6b6435d0  [249, 285, 315, 335, 306, 399, 415, 289, 277, ...   \n",
       "5e9afd56-bb99-11e8-b2b9-ac1f6b6435d0  [146, 261, 288, 368, 269, 211, 156, 208, 195, ...   \n",
       "5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0  [365, 525, 162, 273, 279, 323, 469, 310, 316, ...   \n",
       "...                                                                                 ...   \n",
       "d9d99186-bbca-11e8-b2bc-ac1f6b6435d0  [845, 173, 299, 455, 587, 1127, 659, 811, 395,...   \n",
       "daa22470-bbca-11e8-b2bc-ac1f6b6435d0               [1149, 909, 439, 623, 940, 721, 625]   \n",
       "dc261180-bbca-11e8-b2bc-ac1f6b6435d0  [165, 288, 329, 275, 260, 259, 358, 431, 387, ...   \n",
       "dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0  [357, 325, 425, 345, 515, 527, 251, 424, 343, ...   \n",
       "df573730-bbca-11e8-b2bc-ac1f6b6435d0  [173, 281, 957, 84, 365, 337, 975, 404, 479, 6...   \n",
       "\n",
       "                                                                            boxes_width  \\\n",
       "ID                                                                                        \n",
       "5e22a522-bb99-11e8-b2b9-ac1f6b6435d0  [583, 273, 367, 331, 139, 283, 383, 219, 499, ...   \n",
       "5f79a114-bb99-11e8-b2b9-ac1f6b6435d0  [605, 606, 699, 609, 617, 447, 452, 469, 610, ...   \n",
       "5c801c04-bb99-11e8-b2b9-ac1f6b6435d0  [331, 543, 537, 339, 275, 195, 319, 137, 276, ...   \n",
       "5e9afd56-bb99-11e8-b2b9-ac1f6b6435d0  [205, 209, 283, 129, 231, 179, 210, 162, 126, ...   \n",
       "5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0  [884, 415, 582, 708, 485, 429, 557, 286, 475, ...   \n",
       "...                                                                                 ...   \n",
       "d9d99186-bbca-11e8-b2bc-ac1f6b6435d0  [1093, 607, 437, 655, 741, 387, 483, 265, 422,...   \n",
       "daa22470-bbca-11e8-b2bc-ac1f6b6435d0               [463, 815, 735, 1057, 536, 223, 451]   \n",
       "dc261180-bbca-11e8-b2bc-ac1f6b6435d0  [378, 182, 291, 411, 266, 157, 259, 291, 365, ...   \n",
       "dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0  [399, 512, 591, 695, 461, 437, 333, 507, 615, ...   \n",
       "df573730-bbca-11e8-b2bc-ac1f6b6435d0  [968, 681, 803, 115, 308, 534, 347, 620, 319, ...   \n",
       "\n",
       "                                                                                  boxes  \n",
       "ID                                                                                       \n",
       "5e22a522-bb99-11e8-b2b9-ac1f6b6435d0  [[0, 217, 1798, 2381], [114, 493, 0, 273], [64...  \n",
       "5f79a114-bb99-11e8-b2b9-ac1f6b6435d0  [[0, 433, 0, 605], [0, 599, 568, 1174], [0, 16...  \n",
       "5c801c04-bb99-11e8-b2b9-ac1f6b6435d0  [[0, 249, 42, 373], [0, 285, 1894, 2437], [226...  \n",
       "5e9afd56-bb99-11e8-b2b9-ac1f6b6435d0  [[0, 146, 455, 660], [0, 261, 635, 844], [5, 2...  \n",
       "5f1af6b4-bb99-11e8-b2b9-ac1f6b6435d0  [[0, 365, 0, 884], [0, 525, 766, 1181], [0, 16...  \n",
       "...                                                                                 ...  \n",
       "d9d99186-bbca-11e8-b2bc-ac1f6b6435d0  [[0, 845, 0, 1093], [0, 173, 1122, 1729], [70,...  \n",
       "daa22470-bbca-11e8-b2bc-ac1f6b6435d0  [[0, 1149, 370, 833], [0, 909, 666, 1481], [75...  \n",
       "dc261180-bbca-11e8-b2bc-ac1f6b6435d0  [[0, 165, 78, 456], [0, 288, 459, 641], [0, 32...  \n",
       "dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0  [[0, 357, 0, 399], [0, 325, 249, 761], [0, 425...  \n",
       "df573730-bbca-11e8-b2bc-ac1f6b6435d0  [[0, 173, 0, 968], [0, 281, 779, 1460], [0, 95...  \n",
       "\n",
       "[10412 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47c49422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10412/10412 [00:01<00:00, 6197.56it/s, Loading images path to in memory list]\n"
     ]
    }
   ],
   "source": [
    "# crop_names = \n",
    "crops_path_hdd = []\n",
    "crops_path_ssd = []\n",
    "# labels = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), postfix = \"Loading images path to in memory list\"):\n",
    "    n_box = len(eval(row[\"boxes\"]))\n",
    "    crops_path_ssd.extend([f\"{crop_folder_ssd}{idx}_{i}.png\" for i in range(n_box)])\n",
    "#     labels.extend([row.Label for _ in range(n_box)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e62477df",
   "metadata": {},
   "source": [
    "# Loading all in memory\n",
    "crops = []\n",
    "labels = []\n",
    "for i, (idx, row) in tqdm(enumerate(df.iterrows()), total=len(df)):\n",
    "    n_box = len(eval(row[\"boxes\"]))\n",
    "    crops.extend([PIL.Image.open(f\"{crop_folder_ssd}{idx}_{i}.png\") for i in range(n_box)])\n",
    "    labels.extend([row.Label for _ in range(n_box)])\n",
    "    if i ==1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a18348c",
   "metadata": {},
   "source": [
    "# Loading all in memory\n",
    "crops = []\n",
    "labels = []\n",
    "for i, (idx, row) in tqdm(enumerate(df.iterrows()), total=len(df)):\n",
    "    n_box = len(eval(row[\"boxes\"]))\n",
    "    for j in range(n_box):\n",
    "        with open(f\"{crop_folder_ssd}{idx}_{i}.png\", \"rb\") as f:\n",
    "            crops.append(PIL.Image.open())\n",
    "    crops.extend([ for i in range(n_box)])\n",
    "    labels.extend([row.Label for _ in range(n_box)])\n",
    "    if i ==1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d2f68e3",
   "metadata": {},
   "source": [
    "# Loading all in memory\n",
    "crops = []\n",
    "labels = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), postfix=idx):\n",
    "    n_box = len(eval(row[\"boxes\"]))\n",
    "    crops.extend([PIL.Image.open(f\"{crop_folder_hdd}{idx}_{i}.png\") for i in range(n_box)])\n",
    "    labels.extend([row.Label for _ in range(n_box)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91961092",
   "metadata": {},
   "source": [
    "one_hot_labels = tf.one_hot(labels, len(set(labels)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98b2d9b7",
   "metadata": {},
   "source": [
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb9b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_ds_hdd = tf.data.Dataset.from_tensor_slices(crops_path_hdd)\n",
    "filelist_ds_ssd = tf.data.Dataset.from_tensor_slices(crops_path_ssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2502d",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12a83dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9df04740-bb99-11e8-b2b9-ac1f6b6435d0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(19,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tt = crops_path_ssd[1568]\n",
    "tt = tt.split(\"/\")[-1].split(\"_\")[0]\n",
    "display(tt)\n",
    "display(tf.one_hot(df.loc[tt, \"Label\"], N_LABELS))\n",
    "del tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8f1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath):\n",
    "#     return tf.one_hot(df.loc[tf.strings.split(tf.strings.split(filepath, \"/\")[-1], \"_\")[0], \"Label\"], N_LABELS)\n",
    "    return tf.one_hot(df.loc[filepath.split(\"/\")[-1].split(\"_\")[0], \"Label\"], N_LABELS)\n",
    "\n",
    "def get_crop(filepath):\n",
    "    f_str = filepath.numpy().decode('UTF-8')\n",
    "    return tf.convert_to_tensor(imageio.imread(f_str), dtype=tf.float32), get_label(f_str)\n",
    "#     return tf.convert_to_tensor(imageio.imread(filepath.numpy().decode('UTF-8')), dtype=tf.float32), get_label(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fceeeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(crops_path, train_ratio: float = 0.8, n_prefetch: int = None, shuffle: bool = True):\n",
    "    if shuffle:\n",
    "        crops_path = random.sample(crops_path, len(crops_path))\n",
    "        \n",
    "    if n_prefetch is None:\n",
    "        n_prefetch = MAX_CROPS_PREFETCHED // BATCH_SIZE\n",
    "        print(f\"\\nPREFETCH = {n_prefetch}\\n\")\n",
    "    filelist_ds = tf.data.Dataset.from_tensor_slices(crops_path)\n",
    "    \n",
    "    train_length = int(len(crops_path)*train_ratio)\n",
    "    print(str(train_length))\n",
    "    ret_train = filelist_ds.take(train_length).map(lambda x: tf.py_function(func=get_crop,\n",
    "                        inp=[x],\n",
    "                        Tout=(tf.float32, tf.float32)), \n",
    "                        num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    ret_test = filelist_ds.skip(train_length).map(lambda x: tf.py_function(func=get_crop,\n",
    "                        inp=[x],\n",
    "                        Tout=(tf.float32, tf.float32)), \n",
    "                        num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    print(len(ret_train), len(ret_test))\n",
    "    ### Get delete the \"drop_reminder\" arguemnt ! ###\n",
    "    return ret_train.batch(BATCH_SIZE).prefetch(n_prefetch), ret_test.batch(BATCH_SIZE).prefetch(n_prefetch)\n",
    "# .prefetch(n_prefetch).cache()\n",
    "\n",
    "# .prefetch(n_prefetch).cache()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "997fd0df",
   "metadata": {},
   "source": [
    "train_ratio = 0.80\n",
    "ds_size = len(crops_path_hdd)\n",
    "ds_X_train_hdd = filelist_ds_hdd.take(int(ds_size*train_ratio))\n",
    "ds_X_train_ssd = filelist_ds_ssd.take(int(ds_size*train_ratio))\n",
    "\n",
    "# ds_X_train_hhd = ds_X_train_hdd.prefetch(int(ds_size - ds_size*train_ratio))\n",
    "# ds_X_train_ssd = ds_X_train_ssd.prefetch(int(ds_size - ds_size*train_ratio))\n",
    "\n",
    "ds_X_test_hdd = filelist_ds_hdd.skip(int(ds_size*train_ratio))\n",
    "ds_X_test_ssd = filelist_ds_ssd.skip(int(ds_size*train_ratio))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7d0b0cb",
   "metadata": {},
   "source": [
    "ds_train_hdd = ds_X_train_hdd.map(lambda x: tf.py_function(func=get_crop,\n",
    "                        inp=[x],\n",
    "                        Tout=(tf.float32, tf.float32)), \n",
    "                        num_parallel_calls = tf.data.AUTOTUNE)\n",
    "ds_train_ssd = ds_X_train_ssd.map(lambda x: tf.py_function(func=get_crop,\n",
    "                        inp=[x],\n",
    "                        Tout=(tf.float32, tf.float32)), \n",
    "                        num_parallel_calls = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8724987e",
   "metadata": {},
   "source": [
    "# ds_train_hdd = tf.data.Dataset.zip((ds_X_train_hdd, tf.data.Dataset.from_tensor_slices(one_hot_labels)))\n",
    "# ds_train_ssd = tf.data.Dataset.zip((ds_X_train_ssd, tf.data.Dataset.from_tensor_slices(one_hot_labels)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "546b9673",
   "metadata": {},
   "source": [
    "ds_train_batched_hdd = ds_train_hdd.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "ds_train_batched_ssd = ds_train_ssd.batch(BATCH_SIZE).prefetch(2).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d20149",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65d8d646",
   "metadata": {},
   "source": [
    "model.fit(ds_train_batched_hdd, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90116e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFETCH = 128\n",
      "\n",
      "198616\n",
      "198616 49655\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_test = prepare_dataset(crops_path_ssd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10522c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_metrics = 'val_categorical_accuracy'\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                 monitor=checked_metrics, min_delta=0, patience=5, verbose=0,mode='max', baseline=None,\n",
    "                 restore_best_weights=True)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"\\\\tmp\\\\checkpoint\",\n",
    "    save_weights_only=True,\n",
    "    monitor= checked_metrics,\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [early_stop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.models.load_model(f\"models/conv_smaller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cebf837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 535/6207 [=>............................] - ETA: 40:46 - loss: 0.1356 - categorical_accuracy: 0.4386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-26-f12e410695c0>\", line 1, in <module>\n",
      "    history2 = model.fit(ds_train, validation_data=ds_test, validation_steps = 8, epochs = EPOCHS, callbacks = callbacks)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1100, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 855, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2942, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1918, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 555, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 293, in _fixed_getinnerframes\n",
      "    aux = traceback.extract_tb(etb)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\traceback.py\", line 72, in extract_tb\n",
      "    return StackSummary.extract(walk_tb(tb), limit=limit)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\traceback.py\", line 362, in extract\n",
      "    linecache.checkcache(filename)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\compilerop.py\", line 185, in check_linecache_ipython\n",
      "    linecache._checkcache_ori(*args)\n",
      "  File \"N:\\Conda folders\\envs\\env_tf\\lib\\linecache.py\", line 74, in checkcache\n",
      "    stat = os.stat(fullname)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-f12e410695c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mN:\\Conda folders\\envs\\env_tf\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(ds_train, validation_data=ds_test, validation_steps = 8, epochs = EPOCHS, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "768aa616",
   "metadata": {},
   "source": [
    "model.save(\"models/conv_1\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f63f5c2d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model.predict(tf.reshape(tf.convert_to_tensor(imageio.imread(crops_path_ssd[0]), dtype=tf.float32), (1, SIZE, SIZE, -1)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20376aba",
   "metadata": {},
   "source": [
    "model.save(f\"models/{NAME}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d55bf32",
   "metadata": {},
   "source": [
    "history.history\n",
    "\n",
    "{'loss': [0.15791386365890503,\n",
    "  0.13960184156894684,\n",
    "  0.13329339027404785,\n",
    "  0.12873271107673645],\n",
    " 'categorical_accuracy': [0.3202461004257202,\n",
    "  0.4122830033302307,\n",
    "  0.44535183906555176,\n",
    "  0.4669160544872284],\n",
    " 'val_loss': [0.13732598721981049,\n",
    "  0.13094787299633026,\n",
    "  0.13174323737621307,\n",
    "  0.12881629168987274],\n",
    " 'val_categorical_accuracy': [0.390625, 0.45703125, 0.421875, 0.4375]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59574b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d799b969",
   "metadata": {},
   "source": [
    "# Debug and local performance test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a087c",
   "metadata": {},
   "source": [
    "## Cropping"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d0bf695",
   "metadata": {},
   "source": [
    "def crop_tensor(tensor: tf.Tensor, bbox: list, filter_in : int = None):\n",
    "    crop = tensor[bbox[0]:bbox[1], bbox[2]: bbox[3]]\n",
    "    if filter_in:\n",
    "        crop = tf.where(crop == filter_in, crop, 0)\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b1018cd",
   "metadata": {},
   "source": [
    "bbox1 = tf.constant([10, 20, 30, 40])\n",
    "bbox2 = tf.constant([10, 40, 20, 60])\n",
    "img = tf.random.uniform((100, 100, 100, 100), 0, 100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efafac51",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "tf.image.crop_to_bounding_box(img, *bbox)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "434a8718",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "crop_tensor(img, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea73dc",
   "metadata": {},
   "source": [
    "# \"Equal\" timing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6674580",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "if max(tf.shape(img)[:2]) == 4 :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37669b0d",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "if max(tf.shape(img)[:2]) == 3 :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc9f03da",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "if max(tf.shape(img)[:2].numpy()) == 4 :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d210dd32",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "if max(tf.shape(img)[:2].numpy()) == 3 :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6414c",
   "metadata": {},
   "source": [
    "## Resizing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f4cb9de",
   "metadata": {},
   "source": [
    "def add_margins(crop: tf.Tensor, size: int):\n",
    "\n",
    "    h, w = crop.shape[:2]\n",
    "    dy, dx = (size - h) // 2, (size - w) // 2\n",
    "    ret = tf.pad(crop, ((dy, size - h - dy), (dx, size - w - dx), (0, 0)))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "def resize_crop(crop: tf.Tensor, size: int):\n",
    "\n",
    "    shape = tf.shape(crop)[:2].numpy()\n",
    "\n",
    "    if max(shape) == size:\n",
    "        return crop\n",
    "    if (shape > size).any():\n",
    "        return tf.image.resize_with_pad(crop, size, size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return add_margins(crop, size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5ac0c50",
   "metadata": {},
   "source": [
    "img = tf.random.uniform((3,3,3), 0, 100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd777c1d",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "tf.image.resize_with_pad(img, 5, 5, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "667b0246",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "tf.image.resize_with_pad(img, 5, 5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd445896",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "resize_crop(img, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882b4df",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb7b4b77",
   "metadata": {},
   "source": [
    "class projet\n",
    "\n",
    "\n",
    "    # Partie BBOX\n",
    "    \n",
    "    def bbox(arr):\n",
    "        rows = np.any(arr, axis=1)\n",
    "        cols = np.any(arr, axis=0)\n",
    "        rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "        cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "        return [rmin, rmax, cmin, cmax]\n",
    "\n",
    "\n",
    "    def get_class_bbox(cells: np.array, class_idx: int, pads = None, padding: float = 0.01):\n",
    "        \"\"\"\n",
    "        Padding is used only if pads is None. It will calculate the pads by the size of the image.\n",
    "        \"\"\"\n",
    "        h, w = cells.shape\n",
    "        if pads is None:\n",
    "            pads = int(h * padding), int(w * padding)\n",
    "        bb = bbox(cells==class_idx)\n",
    "        bb[0] = max(bb[0] - pads[0], 0)\n",
    "        bb[1] = min(bb[1] + pads[0], h)\n",
    "        bb[2] = max(bb[2] - pads[1], 0)\n",
    "        bb[3] = min(bb[3] + pads[1], w)\n",
    "        return bb\n",
    "\n",
    "\n",
    "    def getall_bboxes(cells : np.array, padding: float = 0.01):\n",
    "        pads = int(cells.shape[0] * padding), int(cells.shape[1] * padding)\n",
    "        # bounding boxes\n",
    "        bounding_boxes = []\n",
    "        for i in range(1, cells.max()+1 ):\n",
    "            bounding_boxes.append(get_class_bbox(cells, i, pads))\n",
    "    #         show_image((cells==i)[bb[0]:bb[1], bb[2]:bb[3]], \"Blues\")\n",
    "        return bounding_boxes\n",
    "\n",
    "\n",
    "    def crop_array(array: np.array, bbox: list, filter_in : int = None):\n",
    "        crop = array[bbox[0]:bbox[1], bbox[2]: bbox[3]]\n",
    "        if filter_in:\n",
    "            crop = np.where(crop == filter_in, crop, 0)\n",
    "        return crop\n",
    "\n",
    "\n",
    "    # Partie resizing\n",
    "    def resize_down(crop: np.array, size: int):\n",
    "        return cv2.resize(crop, (size, size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def add_margins(crop: np.array, size: int):\n",
    "        ret = np.zeros((size, size, crop.shape[2]))\n",
    "        h, w = crop.shape[:2]\n",
    "        dy, dx = (size - h) // 2, (size - w) // 2\n",
    "        ret[dy : dy + h, dx : dx + w, :] = crop\n",
    "        return ret\n",
    "\n",
    "    def resize_crop(crop: np.array, size: int):\n",
    "        if max(crop.shape[:2]) == size:\n",
    "            return crop\n",
    "        if (np.array(crop.shape[:2]) > size).any():\n",
    "            return resize_down(crop, size)\n",
    "        else:\n",
    "            return add_margins(crop, size)\n",
    "\n",
    "\n",
    "    def get_bboxes(file_path):\n",
    "        return tf.convert_to_tensor(eval(df.loc[file_path.numpy().decode(\"UTF-8\"), \"boxes\"]))\n",
    "    \n",
    "    def get_label(file_path):\n",
    "        return one_hot_labels[df.loc[file_path.numpy().decode(\"UTF-8\"), \"new_index\"]]\n",
    "\n",
    "    def get_nuc_mask(file_path):\n",
    "        return tf.convert_to_tensor(np.load(data_folder+\"hpa_nuclei_mask/\"+file_path.numpy().decode('UTF-8')+\".npz\")[\"arr_0\"].astype(np.uint8))\n",
    "\n",
    "\n",
    "    def get_cell_mask(file_path):\n",
    "        return tf.convert_to_tensor(np.load(data_folder+\"hpa_cell_mask/\"+file_path.numpy().decode('UTF-8')+\".npz\")[\"arr_0\"].astype(np.uint8))\n",
    "\n",
    "\n",
    "    def get_image(file_path):\n",
    "        return tf.convert_to_tensor(imageio.imread((data_folder+\"train/\"+file_path.numpy().decode('UTF-8')+\"_green.png\")))\n",
    "\n",
    "    def crop_tensor(tensor: tf.Tensor, bbox: list, filter_in : int = None):\n",
    "        crop = tensor[bbox[0]:bbox[1], bbox[2]: bbox[3]]\n",
    "        if filter_in:\n",
    "            crop = tf.where(crop == filter_in, crop, 0)\n",
    "        return crop\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def init_model(path=\"models/\"):\n",
    "        self.model = tf.models.load_model(f\"{path}_default.model\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def predict(img_green, mask_cell, mask_nuclei):\n",
    "        composite = ...\n",
    "\n",
    "        results = self.model.predict(composite)\n",
    "        return results.max(), classes[results.argmax()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
